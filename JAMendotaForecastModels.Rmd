---
title: JA Cyanobacteria model with Nino Index Phase Analysis 
---

 
Libraries
```{r Libraries}
library(dplyr)
library(ggplot2)
library(plyr)
library(stringr)
```

Prepare Data

```{r Prepare Data}
#MEI data
df<-read.csv("~/Desktop/PhD/Ideas/June Forecast/mei_phase.csv")

#Remove all other index
df<-df[-24,c(1:2)]

#Other data
basedata<-read.csv("~/Desktop/PhD/Ideas/June Forecast/june_basedata.csv")
disc<-basedata$discharge #Discharge
temp<-basedata$SST #Sea Surface Temp #SST CHANGE
seds <- basedata$sus_seds #suspended sediments short tons/day
phos <- basedata$phosphorus #phosphorus lbs/day
soilm <- basedata$soil_m #Soil moisture kg/m^2
no3no2<-basedata$no3no2_sloh #Nitrate + Nitrate @ buoy
totpuf<-basedata$totpuf_sloh #Total Unfiltered Phosphorus
nipa_sst <- basedata$nipa_sst #NIPA SST PC1
nipa_slp <- basedata$nipa_slp #NIPA SLP PC1
events <- basedata$extevents #Extreme events
modis <- basedata$MODIS #Floating Algae Index
dp <- basedata$Daphnia_pulicaria #D. pulicaria biomass

cyano<-basedata$cyano #Dependent variable


df$discharge <- disc
df$phosphorus <- phos
df$susseds <- seds
df$soilm <- soilm
df$cyano <- cyano
df$no3no2 <- no3no2
df$totpuf <- totpuf
df$nipa_sst <-nipa_sst
df$nipa_slp <- nipa_slp
df$events <- events
df$modis <- modis
df$dp <- dp

#GCV Data frame
GCVneg <- data.frame("GCV"=NA,"m"=NA)
GCVpos <- data.frame("GCV"=NA,"m"=NA)


```

Split Data into Nino Phases

```{r Split Data into Nino Phases}
#Create index
pos <- df$MEI_MJ>=0
neg <- df$MEI_MJ<0

#Apply index to data
pos<-df[pos,]
neg<-df[neg,]


pos
neg


```

Look at plots and correlations for pos and neg phases

```{r Phase correlations}
remove(nipa_cors)
names <- names(pos)


nipa_cors <- data.frame("Predictor"="",
                       "Pearson_corrs"=NA,
                       "Pearson_pvals"=NA,
                       "Spearman_corrs"=NA,
                       "Spearman_pvals"=NA,
                       "Nino Phase" = NA)

for (i in 2:ncol(pos)) {
  pear <- cor.test(pos$cyano, pos[ ,i] , method="pearson")
  spear <- cor.test(pos$cyano, pos[ ,i], method="spearman")
nipa_cors <- rbind(nipa_cors, data.frame("Predictor"=names[i], "Pearson_corrs"=pear$estimate, "Pearson_pvals"=pear$p.value, "Spearman_corrs"=spear$estimate, "Spearman_pvals"=spear$p.value, "Nino Phase"="positive"))
}


for (i in 2:ncol(neg)) {
  pear <- cor.test(neg$cyano, neg[ ,i] , method="pearson")
  spear <- cor.test(neg$cyano, neg[ ,i], method="spearman")
nipa_cors <- rbind(nipa_cors, data.frame("Predictor"=names[i], "Pearson_corrs"=pear$estimate, "Pearson_pvals"=pear$p.value, "Spearman_corrs"=spear$estimate, "Spearman_pvals"=spear$p.value, "Nino Phase"="negative"))
}


format(nipa_cors, scientific=FALSE)
nipa_cors$R_sq <- (nipa_cors$Pearson_corrs)^2
nipa_cors
```

Barplots showing R square b/w phases
```{r R^2 phase barplots}

# barplot<-nipa_cors[c(3,4,8,10,11,12,14,15,19,21,22,23),]
# barplot
# 
# par(las=1)
# par(mar=c(5,8,4,2))
# barplot(barplot$R_sq[barplot$Nino.Phase=="positive"], horiz=TRUE,names.arg = c("Phosphorus","Discharge","Nitrate + Nitrite","SST","SLP","Extreme Events"),cex.names=0.9,xlim=c(0,1), col=c("orange","mediumblue","green3","firebrick2","deepskyblue","purple"),xlab="R-squared")
# 
# 
# par(las=1)
# par(mar=c(5,8,4,2))
# barplot(barplot$R_sq[barplot$Nino.Phase=="negative"], horiz=TRUE,names.arg = c("Phosphorus","Discharge","Nitrate + Nitrite","SST","SLP","Extreme Events"),cex.names=0.9,xlim=c(0,1), col=c("orange","mediumblue","green3","firebrick2","deepskyblue","purple"),xlab="R-squared")
```

Visualize correlations

```{r Visualize correlations}
names <- c("Discharge","Phosphorus","Sediments","Soil Moisture","No2No3 (Buoy)","Total P (Buoy)","SST","SLP","Extreme Events","FAI","D. pulicaria")
nipa_cors_neg<-nipa_cors[-c(1,2,7,15,20),]
nipa_cors_pos<-nipa_cors[-c(1,2,7,15,20),]
#Significant
nipa_cors$significant <- nipa_cors$Pearson_pvals<=0.05&nipa_cors$Spearman_pvals<=0.05
#R squared
par(las=1)
par(mar=c(5,8,4,2))
barplot(nipa_cors_neg$R_sq[nipa_cors_neg$Nino.Phase=="negative"],horiz=TRUE,names.arg = names,col=nipa_cors_neg$significant[nipa_cors_neg$Nino.Phase=="negative"],main = "Negative ENSO Phase",cex.names=0.65,xlim=c(0,1),cex.main=0.9,cex=0.7)

par(las=1)
par(mar=c(5,8,4,2))
barplot(nipa_cors_pos$R_sq[nipa_cors_pos$Nino.Phase=="positive"],horiz=TRUE,names.arg = names,col=nipa_cors_pos$significant[nipa_cors_pos$Nino.Phase=="positive"],main = "Positive ENSO Phase",cex.names=0.65,xlim=c(0,1),cex.main=0.9,cex=0.7)


#Pearson
par(las=2)
par(mar=c(5,8,4,2))
barplot(nipa_cors_neg$Pearson_corrs[nipa_cors_neg$Nino.Phase=="negative"],names.arg = names,col=nipa_cors_neg$significant[nipa_cors_neg$Nino.Phase=="negative"],main = "Negative ENSO Phase",cex.names=0.65,ylim=c(-1,1))


par(las=2)
par(mar=c(5,8,4,2))
barplot(nipa_cors_pos$Pearson_corrs[nipa_cors_pos$Nino.Phase=="positive"],names.arg = names,col=nipa_cors_pos$significant[nipa_cors_pos$Nino.Phase=="positive"],main = "Positive ENSO Phase",cex.names=0.65,ylim=c(-1,1))


#Spearman
par(las=2)
par(mar=c(5,8,4,2))
barplot(nipa_cors_neg$Spearman_corrs[nipa_cors_neg$Nino.Phase=="negative"],names.arg = names,col=nipa_cors_pos$significant[nipa_cors_pos$Nino.Phase=="negative"],main = "Negative nipa")


par(las=2)
par(mar=c(5,8,4,2))
barplot(nipa_cors_neg$Spearman_corrs[nipa_cors_neg$Nino.Phase=="positive"],names.arg = names,col=nipa_cors_pos$significant[nipa_cors_pos$Nino.Phase=="positive"],main = "Positive nipa")
```



Test for statistical difference in mean CB between pos and negative phases

```{r Phase mean CB}

for (i in 1:nrow(df)) {
  if(df$MEI[i]>=0) {df$phase[i] = "positive"}
  else {df$phase[i] = "negative"}
}

t.test(df$cyano~df$phase)
#cyano vals are not significantly different b/w nino phases

 
boxplot(df$cyano ~ df$phase,
        data = df,
        names=c("Negative","Positive"),
        ylab="Cyanobacteria Abundance")


```

Create A dataframe for the NIPA predictions

```{r Begin Model Construction}

NIPA_pcr <- data.frame("Predictions"=NA,"Observed"=NA,"Phase"=NA,"Year"=NA)
```

Construct the prediction model for the negative phase

Libraries
```{r Model Libraries}
library(tidyverse)
library(caret)
library(pls)
library(fitdistrplus)
library(plsVarSel)
library(verification)
```

Negative Phase model scores

```{r Negative_Model_Scores}
#Significant Predictors (Column numbers): Discharge (3), Phosphorus(4), nipa SST (10), no2no3(8),totpuf(9),events(12),suspended seds(5), modis(13)
set.seed(12)

Neg <- neg[,c(3,4,7,10,9,13)]
Neg
a<-subset(Neg, select=-(cyano))

#Look at how many components needed
i<-preProcess(a, method = "pca", thresh = 0.90)
num_comp<-i$numComp


#Change tunelength to # components
model <- train(cyano~., data = Neg, method = "pcr", scale = TRUE, center=TRUE, trControl=trainControl(method="loocv",number=16),tuneLength=num_comp, maximize=TRUE)
model
plot(model)

#X is amount of variance explained
summary(model)

#Best combinations
#neg[,c(3,4,10,13)]
#GCV=0.01408596
#Rsquare=0.74

#neg[,c(3,4,10,8,13)]
#GCV=0.03873417
#Rsquare=0.85

#neg[,c(3,4,10,9,13)]
#GCV=0.01914002
#Rsquare=0.81

```

Predictions - Negative ENSO phase with Leave one out cross validation

```{r Negative_Model_Predictions}


index = seq(1,nrow(neg)) #set up the index
model_drop<-matrix(,nrow=nrow(neg))
year<-neg$year


for (i in seq(1,nrow(Neg))){#drop one year for cross validation
  ind<-index!=i #logical value where each column is true except ncol=i
  train_data<-Neg[ind,] #returns every row of basedata except ind=i
  test_data <- Neg[!ind,]
  model <- train(
  cyano~., data = train_data, method = "pcr",
  scale = TRUE, center=TRUE,tuneLength=num_comp,maximize=TRUE
  )
  prediction <- model %>% predict(test_data, ncomp=num_comp)
  model_drop[i,] = prediction
}


#Add negative phase predictions to the final dataframe

neg$preds <- model_drop

NIPA_pcr<-rbind(NIPA_pcr, data.frame("Predictions"=neg$preds,"Year"=neg$year,"Phase"="Negative","Observed"=neg$cyano))


plot(year,model_drop, type="l",ylab="Predictions") + lines(year,Neg$cyano, col="green")
data.frame(
  RMSE = caret::RMSE(model_drop, Neg$cyano),
  Rsquare = caret::R2(model_drop, Neg$cyano)
)

cor.test(neg$cyano, neg$preds, method="pearson")
cor.test(neg$cyano, neg$preds, method="spearman")

```

Generalized Cross Validated Skill Score
Smallest number is best

```{r GCV_Negative_Phase}
et <- neg$cyano-neg$preds #Observed values minus the predicted values
n = 16 #Number of data points
m = num_comp  #Number of PCs


#Sum of the squared error between observed and predicted value i/number of data points for all predictions - Numerator
for (i in 1:16) {
  GCVnum=sum((et[i]^2)/n)
} 

#Denominator
gcv<-GCVnum/((1-(m/n))^2)  


GCVneg<-rbind(GCVneg,data.frame("GCV"=gcv,"m"=m))
GCVneg
```




Boxplot - Negative phase

```{r Negative Boxplot}
cyano<-Neg$cyano
err<-cyano-t(model_drop) # difference between measurements and predictions
verr<-as.vector(err) #error as a vector
hist(verr)

dist<-fitdist(verr,"norm") # Fitting a normal distribution to the differences b/w the predicted values and the observed values to get values for the boxplot
plot(dist)
summary(dist)
muhat<-dist$estimate[1] #estimate of mean difference between obs and predicted
sigmahat<-dist$estimate[2] #estimate of standard deviation around muhat

rfit<-function(n,r,p1,p2,fit){
  mR<-matrix(,ncol = n,nrow = r)
  for (j in seq(1,n)){
    for (i in seq(1,r)){
    mR[i,j]<-fit(1,p1,p2) #generate random normally distributed variables
    }
  }
  return(mR)
}
r=100 #basically bootstrapping to generate a confidence interval for the data?
n=length(cyano)
Rnorm<-rfit(n,r,muhat,sigmahat,rnorm) # 100 randomly dist numbers generated around the difference between obs and predicted 
yhat<-matrix(rep(model_drop, each = r),ncol=n,nrow=r) # model predictions repeated for 100 rows 
yvarn_neg<-yhat+Rnorm #model predictions + the distributed numbers
yvarn_neg[yvarn_neg<0]<-0

test_stat<-shapiro.test(verr) #testing for normality
test_stat


h1<-boxplot(yvarn_neg,outline = FALSE,xlab = 'Years', ylab = 'JA Average Cyanobacteria Biomass (mg/L)',ylim=c(0,13))
lower<-quantile(Neg$cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(Neg$cyano, prob=.67)
B=rep(lower,n) #33% quantile need to change this so it's not hard coded
N=rep(upper,n) #67% quantile
lines(seq(1,n),cyano,col="blue")
lines(seq(1,n),B,col="black")
lines(seq(1,n),N,col="black")
```

Organize predictions into categories and calculate RPSS Negative Phase

```{r RPSS Negative Phase}

test_stat<-shapiro.test(verr)
test_stat

#Observed
cyanoObs<-matrix(0, nrow=n, ncol=3)
for (i in seq(1,n)){
  if (cyano[i]<=lower){ #how many obs cyano values were in lower third of obs cyano values
    cyanoObs[i,1]<-1
  }
  else if (lower<=cyano[i]&&cyano[i]<=upper){ #middle third
    cyanoObs[i,2]<-1
  }
  else{
    cyanoObs[i,3]<-1 #upper third
  }
}
#Predicted %
percent<-matrix(0,ncol = 3, nrow = n)
for (i in seq(1,n)){
  yvarn_i<-yvarn_neg[,i]
  for (j in seq(1:100)){
    if (yvarn_i[j]<=lower){ #how many predictions were in lower third of obs cyano values
     percent[i,1]<-percent[i,1]+1
    }
    else if (yvarn_i[j]>lower && yvarn_i[j]<upper){ #middle third of obs cyano values
      percent[i,2]<-percent[i,2]+1
    }
    else{
      percent[i,3]<-percent[i,3]+1 #upper third of obs cyano values
    }
  }
}

ncat<-3
numB<-length(cyanoObs[,1][cyanoObs==1]) 
numN<-length(cyanoObs[,2]) 
numA<-length(cyanoObs[,3]) 

perB<-(numB/n)
perN<-(numN/n)
perA<-(numA/n)

dpercent<-percent/100 #forecasted

calc_rps <- function(predicted, observed){
  rps <- 0
  for (i in 1:(length(predicted)-1)) {
    sum_pred <- sum(predicted[1:i])
    sum_obs <- sum(observed[1:i])
    sq_err <- as.numeric((sum_pred-sum_obs)^2)
    rps <- rps + sq_err
  }
  return(rps)
}

rps<-rep(0,n) #initial vector for model RPS values for each year
rps_clim<-rep(0,n) #Same for climatology

for (i in 1:n){
  pred_vector<-as.vector(dpercent[i,])
  obs_vector<-as.vector(cyanoObs[i,])
  
  #calculate RPS for one year
  rps_temp<-calc_rps(pred_vector,obs_vector)
  
  #claculate rps for climatology
  rps_clim_temp<-calc_rps(predicted = rep(0.333333,3),obs_vector)
  
  #store RPS values
  rps[i]<-rps_temp
  rps_clim[i]<-rps_clim_temp
}


rps<-rps/(ncat-1)
rps_clim<-rps_clim/(ncat-1)
rpss<-1-rps/rps_clim
rpss<-median(rpss)
paste("Median RPSS: ",rpss)
```

Hit-Miss Matrix Using distribution calculated for Negative Phase

```{r}
##For calculating HSS
percent_hold<-c(0,0,0)
pred_m<-matrix(0,ncol = 3,nrow = n)
for (i in seq(1:n)){
  percent_hold<-percent[i,]
  if (percent_hold[1]==max(percent_hold)){
    pred_m[i,1]<-1
  }
  else if (percent_hold[2]==max(percent_hold)){
    pred_m[i,2]<-1
  }
  else{
    pred_m[i,3]<-1
  }
}

##For creating the skill matrix
pred_test<-c()
for (i in 1:n){
  percent_hold<-percent[i,] #Take first row from BNA repeated predictions matrix
    if (percent_hold[1]==max(percent_hold)){ #if B is the largest category feed pred_test the lower boundary-1 (presumably to tell it which bin it should be in) Why do it like this??
    pred_test[i]<-lower-1
  }
  else if (percent_hold[2]==max(percent_hold)){
    pred_test[i]<-lower+1
  }
  else{
    pred_test[i]<-upper+1
  }
}

observed_df<-data.frame(year = year[1:n],obs = cyano[1:n])
predicted_df<-data.frame(year = year[1:n], pred = pred_test)
breaks<-c(0,lower,upper, Inf)
labels<-c("Low","Normal","High")
bin_obs<-cut(observed_df$obs,breaks,include.lowest = T,right = F, labels=labels)
summary(bin_obs)
bins_pred <- cut(predicted_df$pred, breaks, include.lowest = T, right=FALSE, labels=labels)
summary(bins_pred)

#create contingency table
observed_df$obs_bins<-bin_obs
observed_df$pred_bins<-bins_pred
skill_matrix<-with(observed_df, table(obs_bins, pred_bins))
skill_matrix



hit_hold<-abs(cyanoObs-pred_m)
miss<-sum(hit_hold)/2
hit<-n-miss
expt_hit<-n/3
HSS<-(hit-expt_hit)/(n-expt_hit)
paste("HSS: ",HSS)
```

Construct the Prediction Model for the Positive phase

```{r Positive_Model_Scores}
set.seed(12)
#Significant Predictors: nipa SST(10) and SLP(11) and MODIS(13) and D. Pulicaria (14)
Pos <- pos[,c(7,10,13)]
Pos
b<-Pos[-1]

preProcess(b, method = "pca", thresh = 0.90)

model <- train(cyano~., data = Pos, method = "pcr", scale = TRUE, center=TRUE, trControl=trainControl(method="loocv",number=7),tuneLength=2)
model

#X is amount of variance explained
summary(model)

#Best combination
#pos[,c(10,13)]
#GCV=0.04
#Rsquare=0.75
```

Predictions - Positive ENSO phase - Leave One out cross validation

```{r Positive_Model_Predictions}
index = seq(1,nrow(pos)) #set up the index
model_drop<-matrix(,nrow=nrow(pos))
year<-pos$year

for (i in seq(1,nrow(Pos))){#drop one year for cross validation
  ind<-index!=i #logical value where each column is true except ncol=i
  train_data<-Pos[ind,] #returns every row of basedata except ind=i
  test_data <- Pos[!ind,]
  model <- train(
  cyano~., data = train_data, method = "pcr", 
  scale = TRUE, center=TRUE, tuneLength=1,maximize=TRUE
  )
  prediction <- model %>% predict(test_data, ncomp=1)
  model_drop[i,] = prediction
}

pos$preds <- model_drop


NIPA_pcr<-rbind(NIPA_pcr, data.frame("Predictions"=pos$preds,"Year"=pos$year,"Phase"="Positive","Observed"=pos$cyano))

plot(year,model_drop, type="l",ylab="Predictions") + lines(year,Pos$cyano, col="green")
data.frame(
  RMSE = caret::RMSE(model_drop, Pos$cyano),
  Rsquare = caret::R2(model_drop, Pos$cyano)
)


cor.test(pos$cyano, pos$preds, method="pearson")
cor.test(pos$cyano, pos$preds, method="spearman")
summary(model)
```

Generalized Cross Validated Skill Score Positive Phase

```{r GCV_Positive_Phase}
et <- pos$cyano-pos$preds #Observed values minus the predicted values
n = 7 #Number of data points
m = 1  #Number of PCs


#Sum of the squared error between observed and predicted value i/number of data points for all predictions - Numerator
for (i in 1:7) {
  GCVnum=sum((et[i]^2)/n)
} 

#Denominator
gcv<-GCVnum/((1-(m/n))^2)  


GCVpos<-rbind(GCVpos,data.frame("GCV"=gcv,"m"=m))
GCVpos
```


Boxplot - positive Phase

```{r}
cyano<-pos$cyano
err<-cyano-t(model_drop) # difference between measurements and predictions
verr<-as.vector(err) #error as a vector
hist(verr)

dist<-fitdist(verr,"norm") # Fitting a normal distribution to the differences b/w the predicted values and the observed values to get values for the boxplot
plot(dist)
summary(dist)
muhat<-dist$estimate[1] #estimate of mean difference between obs and predicted
sigmahat<-dist$estimate[2] #estimate of standard deviation around muhat

rfit<-function(n,r,p1,p2,fit){
  mR<-matrix(,ncol = n,nrow = r)
  for (j in seq(1,n)){
    for (i in seq(1,r)){
    mR[i,j]<-fit(1,p1,p2) #generate random normally distributed variables
    }
  }
  return(mR)
}
r=100 #basically bootstrapping to generate a confidence interval for the data?
n=length(cyano)
Rnorm<-rfit(n,r,muhat,sigmahat,rnorm) # 100 randomly dist numbers generated around the difference between obs and predicted 
yhat<-matrix(rep(model_drop, each = r),ncol=n,nrow=r) # model predictions repeated for 100 rows 
yvarn_pos<-yhat+Rnorm #model predictions + the distributed numbers
yvarn_pos[yvarn_pos<0]<-0

test_stat<-shapiro.test(verr) #testing for normality
test_stat

h1<-boxplot(yvarn_pos,outline = FALSE,xlab = 'Years', ylab = 'JA Average Cyanobacteria Biomass (mg/L)',ylim=c(0,13))
lower<-quantile(Neg$cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(Neg$cyano, prob=.67)
B=rep(lower,n) #33% quantile need to change this so it's not hard coded
N=rep(upper,n) #67% quantile
lines(seq(1,n),cyano,col="blue")
lines(seq(1,n),B,col="black")
lines(seq(1,n),N,col="black")
```


Boxplot - combined 

```{r}
NIPA_pcr<-NIPA_pcr[-1, ]
n=nrow(NIPA_pcr)
year<-NIPA_pcr$Year

yvarn<-cbind(yvarn_neg,yvarn_pos)
yvarn<-t(yvarn)
yvarn <-cbind(yvarn,year)

yvarn_ordered<-yvarn[order(year),]
yvarn_ordered<-yvarn_ordered[ ,-101]
yvarn_ordered<-t(yvarn_ordered)

#col=c("blue","red","blue","blue","red","red","red","blue","red","red","blue","red","red","red","red","red","red","red","red","red","blue","blue","red"

h1<-boxplot(yvarn_ordered, outline = FALSE, xlab = 'Years', ylab = 'JA Average Cyanobacteria Biomass (mg/L)',ylim=c(0,17), names=c(df$year),col=c("lightskyblue","indianred1","lightskyblue","lightskyblue","indianred1","indianred1","indianred1","lightskyblue","indianred1","indianred1","lightskyblue","indianred1","indianred1","indianred1","indianred1","indianred1","indianred1","indianred1","indianred1","indianred1","lightskyblue","lightskyblue","indianred1"))
#legend(20, y=13, legend=c("Negative", "Positive"), cex=0.8,fill=c("indianred1","lightskyblue"))
lower<-quantile(df$cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(df$cyano, prob=.67)
B=rep(lower,n) #33% quantile need to change this so it's not hard coded
N=rep(upper,n) #67% quantile
lines(seq(1,n),df$cyano,col="black",lwd=1.4)
lines(seq(1,n),B,col="black")
lines(seq(1,n),N,col="black")



h1<-boxplot(yvarn_ordered, outline = FALSE, xlab = 'Years', ylab = 'JA Average Cyanobacteria Biomass (mg/L)',ylim=c(0,17), names=c(df$year),col="gray90")
lower<-quantile(df$cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(df$cyano, prob=.67)
B=rep(lower,n) #33% quantile need to change this so it's not hard coded
N=rep(upper,n) #67% quantile
lines(seq(1,n),df$cyano,col="mediumturquoise",lwd=2)
lines(seq(1,n),B,col="black")
lines(seq(1,n),N,col="black")

```

Calculate RPSS for combined model

```{r}
cyano <- df$cyano

#Observed
cyanoObs<-matrix(0, nrow=n, ncol=3)
for (i in seq(1,n)){
  if (cyano[i]<=lower){ #how many obs cyano values were in lower third of obs cyano values
    cyanoObs[i,1]<-1
  }
  else if (lower<=cyano[i]&&cyano[i]<=upper){ #middle third
    cyanoObs[i,2]<-1
  }
  else{
    cyanoObs[i,3]<-1 #upper third
  }
}
#Predicted %
percent<-matrix(0,ncol = 3, nrow = n)
for (i in seq(1,n)){
  yvarn_i<-yvarn_ordered[,i]
  for (j in seq(1:100)){
    if (yvarn_i[j]<=lower){ #how many predictions were in lower third of obs cyano values
     percent[i,1]<-percent[i,1]+1
    }
    else if (yvarn_i[j]>lower && yvarn_i[j]<upper){ #middle third of obs cyano values
      percent[i,2]<-percent[i,2]+1
    }
    else{
      percent[i,3]<-percent[i,3]+1 #upper third of obs cyano values
    }
  }
}

ncat<-3
numB<-length(cyanoObs[,1][cyanoObs==1]) 
numN<-length(cyanoObs[,2]) 
numA<-length(cyanoObs[,3]) 

perB<-(numB/n)
perN<-(numN/n)
perA<-(numA/n)

dpercent<-percent/100 #forecasted

calc_rps <- function(predicted, observed){
  rps <- 0
  for (i in 1:(length(predicted)-1)) {
    sum_pred <- sum(predicted[1:i])
    sum_obs <- sum(observed[1:i])
    sq_err <- as.numeric((sum_pred-sum_obs)^2)
    rps <- rps + sq_err
  }
  return(rps)
}

rps<-rep(0,n) #initial vector for model RPS values for each year
rps_clim<-rep(0,n) #Same for climatology

for (i in 1:n){
  pred_vector<-as.vector(dpercent[i,])
  obs_vector<-as.vector(cyanoObs[i,])
  
  #calculate RPS for one year
  rps_temp<-calc_rps(pred_vector,obs_vector)
  
  #claculate rps for climatology
  rps_clim_temp<-calc_rps(predicted = rep(0.333333,3),obs_vector)
  
  #store RPS values
  rps[i]<-rps_temp
  rps_clim[i]<-rps_clim_temp
}

rps<-rps/(ncat-1)
mean_rps<-mean(rps)
median_rps<-median(rps)

rps_clim<-rps_clim/(ncat-1)
mean_rps_clim<-mean(rps_clim)
median_rps_clim<-median(rps_clim)

#Find RPSS for above-normal category
up_ind<-df$cyano>upper
1-median(rps[up_ind])/median(rps_clim[up_ind])

rpss<-1-mean_rps/mean_rps_clim
rpss_median<-1-median_rps/median_rps_clim
paste("Mean RPSS: ",rpss)
paste("Median RPSS: ",rpss_median)

```

HSS and skill matrix 

```{r}

ensemble_hss=TRUE

##For calculating HSS using the ensemble (greatest percent in category)
percent_hold<-c(0,0,0)
pred_m<-matrix(0,ncol = 3,nrow = n)
for (i in seq(1:n)){
  percent_hold<-percent[i,]
  if (percent_hold[1]==max(percent_hold)){
    pred_m[i,1]<-1
  }
  else if (percent_hold[2]==max(percent_hold)){
    pred_m[i,2]<-1
  }
  else{
    pred_m[i,3]<-1
  }
}


# ##For calculating HSS using deterministic preds
# percent_hold<-c(0,0,0)
# pred_m<-matrix(0,ncol = 3,nrow = n)
# for (i in seq(1:n)){
#   percent_hold<-NIPA_pcr$Predictions[i]
#   if (percent_hold[1]<lower){
#     pred_m[i,1]<-1
#   }
#   else if (percent_hold[1]>=lower&percent_hold[1]<upper){
#     pred_m[i,2]<-1
#   }
#   else{
#     pred_m[i,3]<-1
#   }
# }



##For creating the skill matrix
pred_test<-c()
for (i in 1:n){
  percent_hold<-percent[i,] #Take first row from BNA repeated predictions matrix
    if (percent_hold[1]==max(percent_hold)){ #if B is the largest category feed pred_test the lower boundary-1 (presumably to tell it which bin it should be in) Why do it like this?? 
    pred_test[i]<-lower-1
  }
  else if (percent_hold[2]==max(percent_hold)){
    pred_test[i]<-lower+1
  }
  else{
    pred_test[i]<-upper+1
  }
}

observed_df<-data.frame(year = year[1:n],obs = cyano[1:n])
predicted_df<-data.frame(year = year[1:n], pred = pred_test)
breaks<-c(0,lower,upper, Inf)
labels<-c("Low","Normal","High")
bin_obs<-cut(observed_df$obs,breaks,include.lowest = T,right = F, labels=labels)
summary(bin_obs)
bins_pred <- cut(predicted_df$pred, breaks, include.lowest = T, right=FALSE, labels=labels)
summary(bins_pred)

# #For creating skill matrix with deterministic preds
# bin_obs<-cut(NIPA_pcr$Observed,breaks,include.lowest = T,right = F, labels=labels)
# summary(bin_obs)
# bins_pred <- cut(NIPA_pcr$Predictions, breaks, include.lowest = T, right=FALSE, labels=labels)
# summary(bins_pred)



#create contingency table
observed_df$obs_bins<-bin_obs
observed_df$pred_bins<-bins_pred
skill_matrix<-with(observed_df, table(pred_bins, obs_bins))
skill_matrix


hit_hold<-abs(cyanoObs-pred_m)
miss<-sum(hit_hold)/2
hit<-n-miss
expt_hit<-n/3
HSS<-(hit-expt_hit)/(n-expt_hit)
paste("HSS: ",HSS)

#From verification package (Skill matrix columns assumed obs and rows predictions)
multi.cont(skill_matrix)


#

```

Correlations for the full model

```{r Cors full model}
cor.test(NIPA_pcr$Predictions, NIPA_pcr$Observed, method="pearson")
cor.test(NIPA_pcr$Predictions, NIPA_pcr$Observed, method="spearman")

data.frame(
  RMSE = caret::RMSE(NIPA_pcr$Predictions, NIPA_pcr$Observed ),
  Rsquare = caret::R2(NIPA_pcr$Predictions,NIPA_pcr$Observed)
)
```



Look at years the model does poorly

```{r}
#Diagnose Pos 1998 and 2005
a<-scale(pos$nipa_sst, center = TRUE, scale=TRUE)
b<-scale(pos$events, center = TRUE, scale=TRUE)
c <-scale(pos$cyano, center = TRUE, scale=TRUE)


plot(pos$year,a, type = "l", col="red") + lines(pos$year,b, col="blue") + lines(pos$year,c, col="green")
legend(2007, y=0, legend=c("Cyanobacteria", "SST", "Events"), cex=0.8,fill=c("green","red", "blue"))
```


```{r}
#Diagnose 2014 Negative phase
a<-scale(neg$nipa_sst, center = TRUE, scale=TRUE)
b<-scale(neg$discharge, center = TRUE, scale=TRUE)
c <-scale(neg$cyano, center = TRUE, scale=TRUE)
d<-scale(neg$totpuf, center = TRUE, scale=TRUE)
e<-scale(neg$phosphorus, center = TRUE, scale=TRUE)
f<-scale(neg$no3no2, center = TRUE, scale=TRUE)

plot(neg$year,a, type = "l", col="red", ylim = c(-4,4)) + lines(neg$year,b, col="blue") + lines(neg$year,c, col="green") + lines(neg$year,d, col="black") + lines(neg$year,e, col="purple") + lines(neg$year,f, col="orange")
legend(2000, y=4, legend=c("Cyanobacteria", "SST", "Discharge", "totpuf", "Phosphorus", "FAI"), cex=0.8,fill=c("green","red", "blue", "black", "purple", "orange"))



```

Figure of one-phase, two-phase, and observed timeseries

```{r Figure one-phase, two-phase, and observed timeseries}
library(ggplot2)
opp<-read.csv("~/Desktop/PhD/Ideas/June Forecast/One_Phase_Predictions.csv")

NIPA_pcr<-NIPA_pcr[order(NIPA_pcr$Year),]

#One phase correlations
data.frame(
  RMSE = caret::RMSE(opp$One_Phase_Predictions, opp$Observations),
  Rsquare = caret::R2(opp$One_Phase_Predictions,opp$Observations)
)


fig<-data.frame("Data"=c(NIPA_pcr$Observed,NIPA_pcr$Predictions,opp$One_Phase_Predictions),"Group"=NA,"Year"=c(NIPA_pcr$Year,NIPA_pcr$Year,NIPA_pcr$Year))
fig[1:23,2] = "Observations"
fig[24:46,2] = "Two-Phase Model"
fig[47:69,2] = "One-Phase Model"
fig


plot(NIPA_pcr$Observed, type="l") + lines(NIPA_pcr$Predictions,col="green") + lines(opp$One_Phase_Predictions, col="red")

ggplot(fig, aes(Year, Data, group=Group)) + geom_line(aes(color=Group, linetype=Group)) + scale_color_grey()  + theme_classic() + theme(legend.position="bottom") + xlab("") + ylab("JA Average Cyanobacteria Abundance (mg/L)") + scale_linetype_manual(values=c("solid","dotted", "twodash")) +scale_color_manual(values=c("gray20", "black", "gray42")) + theme(legend.title=element_blank())


fig2<-data.frame("Obs"=NIPA_pcr$Observed,"Group"=NA, "Data"=c(NIPA_pcr$Predictions,opp$One_Phase_Predictions))
fig2[1:23,2] = "Two-phase Model"
fig2[24:46,2] = "One-phase Model"
fig2

caret::R2(fig2$Obs[fig2$Group=="Two-phase Model"],fig2$Data[fig2$Group=="Two-phase Model"])
caret::R2(fig2$Obs[fig2$Group=="One-phase Model"],fig2$Data[fig2$Group=="One-phase Model"])

ggplot(fig2, aes(x=Obs, y=Data, color=Group)) + 
  geom_point() + scale_color_manual(values=c(16, 1))  + 
  theme_bw() + 
  theme(legend.position="bottom") + 
  ylab("Hindcast Predictions (mg/L)") + 
  xlab("JA Average Cyanobacteria Abundance (mg/L)") +
  theme(legend.title=element_blank()) + 
  theme(panel.grid.minor.x=element_blank(), panel.grid.major.x=element_blank()) + 
  geom_smooth(method=lm, se=F, fullrange=TRUE) + 
  annotate(geom="text", x=8.6, y=1.5, label="bold(R) ^ bold(2)",color="black", parse=TRUE) +
  annotate(geom="text", x=10, y=1, label="Two-phase : 0.80",color="black",size=3)+ 
  annotate(geom="text", x=10, y=2, label="One-phase : 0.66",color="black",size=3) +
  geom_abline(linetype="dashed", col="gray")+coord_fixed(ratio=0.6)


cor.test(opp$One_Phase_Predictions, opp$Observations, method="pearson")
cor.test(opp$One_Phase_Predictions, opp$Observations, method="spearman")

```

compare to seasonal model


JA obs probability density
```{r Compare to seasonal model}
JJA<-read.csv("~/Desktop/PhD/Ideas/Cyano/JJA_preds.csv")

plot(NIPA_pcr$Predictions, type = "l",col="blue") + lines(JJA$predictions,col="red") + lines(NIPA_pcr$Observed) + lines(JJA$B) + lines(JJA$N) + lines(B, col="gray") + lines(N, col="gray")

lowerJJA<-JJA$B[1]
upperJJA<-JJA$N[1]

kdensobs<-density(NIPA_pcr$Observed)
kdenssim<-density(NIPA_pcr$Predictions)
kdenJJA <- density(JJA$predictions)
#kdenJJAobs <- density(JJA$cyano)
plot(kdensobs,xlim=c(1,12),ylim=c(0,.45),xlab="Cyanobacteria Biomass (mg/L)",main="Probability Density (1995-2017)", ylab="Probability", col = "blue", lwd = 2)
lines(kdenssim,col="red", lwd = 2)
lines(kdenJJA,col="green", lwd = 2)
#lines(kdenJJAobs,col="purple",lwd=2)
lines(x=c(lower,lower),y=c(-0.1,.46))
lines(x=c(upper,upper),y=c(-0.1,.46)) 
lines(x=c(lowerJJA,lowerJJA),y=c(-0.1,.46),lty=2)
lines(x=c(upperJJA,upperJJA),y=c(-0.1,.46),lty=2)
legend("topright",legend = c("JA Cyanobacteria Obs","Sub-seasonal Model","Seasonal Model","Seasonal (Below, Above)","Sub-seasonal (Below, Above)"),col = c("blue","red","green","black","black"), lty = c(1,1,1,2),lwd=c(2,2,1,1))




density_fig<-data.frame("Data"=c(NIPA_pcr$Observed,NIPA_pcr$Predictions,JJA$predictions),"Group"=NA,"Year"=c(NIPA_pcr$Year,NIPA_pcr$Year,NIPA_pcr$Year))
density_fig[1:23,2] = "July-August Observations"
density_fig[24:46,2] = "Sub-seasonal"
density_fig[47:69,2] = "Seasonal"
density_fig


#Probability density graph of Seasonal, sub seasonal, and observations from 1995-2017
ggplot(density_fig, aes(Data, group=Group)) + 
  geom_density(aes(x=Data, fill=Group, alpha=0.4)) + 
  theme_bw() + geom_vline(aes(slope=0,xintercept=lower))+ 
  geom_vline(aes(slope=0,xintercept=upper))+ 
  theme(panel.grid.minor.x=element_blank(), panel.grid.major.x=element_blank())+ theme(legend.position="bottom")+ 
  xlab("Average cyanobacteria abundance (mg/L)") + 
  ylab("Probability Density") + 
  theme(legend.title=element_blank())+ 
  geom_vline(slope=0,xintercept=lowerJJA,linetype="dotted")+ 
  geom_vline(slope=0,xintercept=upperJJA,linetype="dotted")+ guides(size = "legend", alpha="none") +
  scale_x_continuous(breaks = c(0,2.5,5,7.5,10,12.5))



ks.test(density_fig[density_fig$Group=="Seasonal","Data"],density_fig[density_fig$Group=="July-August Observations","Data"])

ks.test(density_fig[density_fig$Group=="Sub-seasonal","Data"],density_fig[density_fig$Group=="July-August Observations","Data"])

ks.test(density_fig[density_fig$Group=="Sub-seasonal","Data"],density_fig[density_fig$Group=="Seasonal","Data"])


```



```{r Build Figures etc.}
JAnorm<-(NIPA_pcr$Predictions-mean(NIPA_pcr$Predictions))/(sd(NIPA_pcr$Predictions))

Obsnorm<-(NIPA_pcr$Observed-mean(NIPA_pcr$Observed))/(sd(NIPA_pcr$Observed))

JJAnorm<-(JJA$predictions-mean(JJA$predictions))/(sd(JJA$predictions))

lowerN <- quantile(Obsnorm, 0.33)
upperN <- quantile(Obsnorm, 0.66)
Bn=rep(lowerN,n) #33% quantile need to change this so it's not hard coded
Un=rep(upperN,n) #67% quantile

plot(Obsnorm) + lines(JJAnorm) + lines(JAnorm, col="blue")
lines(seq(1,23),Bn)
lines(seq(1,23),Un)



forecast_comp<-data.frame("Year"=year[order(year)],"Observed"=NA,"sub_seas"=NA,"seasonal"=NA)

for (i in 1:23) {if (Obsnorm[i]>upperN) {
  forecast_comp$Observed_cat[i]="High"
  forecast_comp$Observed[i]=3
}
else if (Obsnorm[i]<lowerN) {
  forecast_comp$Observed_cat[i]="Low"
  forecast_comp$Observed[i]=1
} 
  else {
    forecast_comp$Observed_cat[i]="Normal"
    forecast_comp$Observed[i]=2
  }
}


for (i in 1:23) {if (JAnorm[i]>upperN) {
  forecast_comp$sub_seas[i]=3
}
else if (JAnorm[i]<lowerN) {
  forecast_comp$sub_seas[i]=1
} 
  else {
    forecast_comp$sub_seas[i]=2
  }
}

for (i in 1:23) {if (JJAnorm[i]>upperN) {
  forecast_comp$seasonal[i]=3
}
else if (JJAnorm[i]<lowerN) {
  forecast_comp$seasonal[i]=1
} 
  else {
    forecast_comp$seasonal[i]=2
  }
}

forecast_comp$Sub_seas_correct<-forecast_comp$Observed==forecast_comp$sub_seas

forecast_comp$Seasonal_correct<-forecast_comp$Observed==forecast_comp$seasonal

forecast_comp

plot(forecast_comp$Year,forecast_comp$Observed) + lines(forecast_comp$Year,forecast_comp$sub_seas, col="blue") + lines(forecast_comp$Year,forecast_comp$seasonal, col="red")


hit_miss <- forecast_comp[order(forecast_comp$Observed_cat),-c(2,3,4)]
hit_miss$Improvement<-hit_miss$Seasonal_correct==FALSE & hit_miss$Sub_seas_correct==TRUE

hit_miss[hit_miss$Seasonal_correct==TRUE,]
hit_miss[hit_miss$Seasonal_correct==FALSE,]

hit_miss[hit_miss$Observed_cat=="High",]
hit_miss[hit_miss$Observed_cat=="Normal",]
hit_miss[hit_miss$Observed_cat=="Low",]

hit_miss[order(hit_miss$Year),]

#write.csv(hit_miss,"~/Desktop/Forecast_comparison.csv")


density_fig_n<-data.frame("Data"=c(Obsnorm,JAnorm,JJAnorm),"Group"=NA,"Year"=c(NIPA_pcr$Year,NIPA_pcr$Year,NIPA_pcr$Year))
density_fig_n[1:23,2] = "July-August Observations"
density_fig_n[24:46,2] = "Sub-seasonal"
density_fig_n[47:69,2] = "Seasonal"
density_fig_n

#Probability density graph of NORMALIZED Seasonal, sub seasonal, and observations from 1995-2017
ggplot(density_fig_n, aes(Data, group=Group)) + geom_density(aes(x=Data, fill=Group, alpha=0.3)) + theme_bw() + geom_vline(aes(slope=0,xintercept=lowerN))+ geom_vline(aes(slope=0,xintercept=upperN))+ theme(panel.grid.minor.x=element_blank(), panel.grid.major.x=element_blank())+ theme(legend.position="bottom")+ xlab("Average cyanobacteria abundance (mg/L)") + ylab("Probability Density") + theme(legend.title=element_blank())+ guides(size = "legend", alpha="none") + scale_x_continuous(breaks = c(0,2.5,5,7.5,10,12.5))



```




```{r}
#write.csv(nipa_cors,"~/Desktop/PhD/Ideas/June Forecast/NIPA_correlations.csv")
```


```{r}
JJA<-read.csv("~/Desktop/PhD/Ideas/Cyano/JJA_preds.csv")
cyano<-JJA$cyano
model_drop <- JJA$predictions
lower<-quantile(JJA$cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(JJA$cyano, prob=.67)


err<-cyano-t(model_drop) # difference between measurements and predictions
verr<-as.vector(err) #error as a vector
hist(verr)

dist<-fitdist(verr,"norm") # Fitting a normal distribution to the differences b/w the predicted values and the observed values to get values for the boxplot
plot(dist)
summary(dist)
muhat<-dist$estimate[1] #estimate of mean difference between obs and predicted
sigmahat<-dist$estimate[2] #estimate of standard deviation around muhat

rfit<-function(n,r,p1,p2,fit){
  mR<-matrix(,ncol = n,nrow = r)
  for (j in seq(1,n)){
    for (i in seq(1,r)){
    mR[i,j]<-fit(1,p1,p2) #generate random normally distributed variables
    }
  }
  return(mR)
}
r=100 #basically bootstrapping to generate a confidence interval for the data?
n=length(cyano)
Rnorm<-rfit(n,r,muhat,sigmahat,rnorm) # 100 randomly dist numbers generated around the difference between obs and predicted 
yhat<-matrix(rep(model_drop, each = r),ncol=n,nrow=r) # model predictions repeated for 100 rows 
yvarn_neg<-yhat+Rnorm #model predictions + the distributed numbers
yvarn_neg[yvarn_neg<0]<-0


#Observed
cyanoObs<-matrix(0, nrow=n, ncol=3)
for (i in seq(1,n)){
  if (cyano[i]<=lower){ #how many obs cyano values were in lower third of obs cyano values
    cyanoObs[i,1]<-1
  }
  else if (lower<=cyano[i]&&cyano[i]<=upper){ #middle third
    cyanoObs[i,2]<-1
  }
  else{
    cyanoObs[i,3]<-1 #upper third
  }
}
#Predicted %
percent<-matrix(0,ncol = 3, nrow = n)
for (i in seq(1,n)){
  yvarn_i<-yvarn_neg[,i]
  for (j in seq(1:100)){
    if (yvarn_i[j]<=lower){ #how many predictions were in lower third of obs cyano values
     percent[i,1]<-percent[i,1]+1
    }
    else if (yvarn_i[j]>lower && yvarn_i[j]<upper){ #middle third of obs cyano values
      percent[i,2]<-percent[i,2]+1
    }
    else{
      percent[i,3]<-percent[i,3]+1 #upper third of obs cyano values
    }
  }
}

ncat<-3
numB<-length(cyanoObs[,1][cyanoObs==1]) 
numN<-length(cyanoObs[,2]) 
numA<-length(cyanoObs[,3]) 

perB<-(numB/n)
perN<-(numN/n)
perA<-(numA/n)

dpercent<-percent/100 #forecasted

calc_rps <- function(predicted, observed){
  rps <- 0
  for (i in 1:(length(predicted)-1)) {
    sum_pred <- sum(predicted[1:i])
    sum_obs <- sum(observed[1:i])
    sq_err <- as.numeric((sum_pred-sum_obs)^2)
    rps <- rps + sq_err
  }
  return(rps)
}

rps<-rep(0,n) #initial vector for model RPS values for each year
rps_clim<-rep(0,n) #Same for climatology

for (i in 1:n){
  pred_vector<-as.vector(dpercent[i,])
  obs_vector<-as.vector(cyanoObs[i,])
  
  #calculate RPS for one year
  rps_temp<-calc_rps(pred_vector,obs_vector)
  
  #claculate rps for climatology
  rps_clim_temp<-calc_rps(predicted = rep(0.333333,3),obs_vector)
  
  #store RPS values
  rps[i]<-rps_temp
  rps_clim[i]<-rps_clim_temp
}

rps<-rps/(ncat-1)
mean_rps<-mean(rps)
median_rps<-median(rps)


rps_clim<-rps_clim/(ncat-1)
mean_rps_clim<-mean(rps_clim)
median_rps_clim<-median(rps_clim)

#Find RPSS for above-normal category
up_ind<-JJA$cyano>upper
1-median(rps[up_ind])/median(rps_clim[up_ind])

rpss<-1-mean_rps/mean_rps_clim
rpss_median<-1-median_rps/median_rps_clim
paste("Mean RPSS: ",rpss)
paste("Median RPSS: ",rpss_median)

JJA$years<-c(1995:2017)
#Seasonal forecast figure
h1<-boxplot(yvarn_neg, outline = FALSE, xlab = 'Years', ylab = 'JA Average Cyanobacteria Biomass (mg/L)',ylim=c(0,10), names=c(JJA$years),col="gray90")
lower<-quantile(cyano, prob=.33) #lower third of obs cyano values
upper<-quantile(cyano, prob=.67)
B=rep(lower,n) #33% quantile need to change this so it's not hard coded
N=rep(upper,n) #67% quantile
lines(seq(1,n),JJA$cyano,col="mediumturquoise",lwd=2)
lines(seq(1,n),B,col="black")
lines(seq(1,n),N,col="black")


```


